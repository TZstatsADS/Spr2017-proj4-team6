---
title: "Script to test feature extraction"
output: html_notebook
---

### Step 0: Setup project directory and dependencies
First we have to construct a citation vector from the co-author column of our dataset
```{r "setup", include=FALSE}
packages.used=c("knitr", "tidyr", "tidytext",
                "kernlab", "dplyr", "readr",
                "tm", "tibble", "stringr", "qlcMatrix")

# check packages that need to be installed.
packages.needed=setdiff(packages.used, 
                        intersect(installed.packages()[,1], 
                                  packages.used))
# install additional packages
if(length(packages.needed)>0){
  install.packages(packages.needed, dependencies = TRUE)
}

library(knitr)
library(tidyr)
library(tidytext)
library(kernlab)
library(dplyr)
library(readr)
library(tm)
library(tibble)
library(stringr)
library(qlcMatrix)

opts_knit$set(root.dir = normalizePath(".."))
projDir <- opts_knit$get("root.dir")
projDir
```

### Step 1: Create document term matrix
We use the `tm` package to create a corpus of the title strings.
```{r include=FALSE}
source(file.path(projDir,'lib','feature_extraction.R'))
files <- list.files(file.path(projDir,"output"), pattern = "*.csv")

exFilePath <- file.path(projDir,'output','AKumar.csv')
text <- readTextFile(exFilePath)
authorId <- text$AuthorID
dtm <- createCitationMatrix(text)
dtm_train_tfidf <- weightTfIdf(dtm,normalize = FALSE)
```

### Step 2: Run teacher's clustering algorithm from `kernlab` package
```{r, include=FALSE}
start.time <- Sys.time()
result_sclust <- specc(as.matrix(dtm_train_tfidf), 
                       centers=length(unique(authorId)))
end.time <- Sys.time()
time_sclust <- end.time - start.time
```

### Step 3: Run our spectral clustering algorithm in `lib/SpectralClustering.R`
```{r include=FALSE}
source(file.path(projDir,"lib","SpectralClustering.R"))
start.time <- Sys.time()
docsdissim <- cosSparse(t(as.matrix(dtm_train_tfidf)))
## apply K-WAY SPECTRAL CLUSTERING
k <- length(unique(authorId))
result_sQRclust <- specClustering(as.matrix(docsdissim), k)
end.time <- Sys.time()
time_sQRclust <- end.time - start.time
```

### Step 4: Run evaluation metrics on both methods and compare
```{r}
source(file.path(projDir,"lib",'evaluation_measures.R'))
matching_matrix_sclust <- matching_matrix(authorId,result_sclust)
matching_matrix_sQRclust <- matching_matrix(authorId, result_sQRclust)
performance_sclust <- performance_statistics(matching_matrix_sclust)
performance_sQRclust <- performance_statistics(matching_matrix_sQRclust)
```

```{r}
compare_df <- data.frame(method=c("Teacher","Group_6"),
                         precision=c(performance_sclust$precision, performance_sQRclust$precision),
                         recall=c(performance_sclust$recall, performance_sQRclust$recall),
                         f1=c(performance_sclust$f1, performance_sQRclust$f1),
                         accuracy=c(performance_sclust$accuracy, performance_sQRclust$accuracy),
                         mcc=c(performance_sclust$mcc, performance_sQRclust$mcc),
                         time=c(time_sclust,time_sQRclust))
kable(compare_df,caption="Comparision of performance for two clustering methods",digits = 2)
```

```{r}
files <- list.files(file.path(projDir,"output"), pattern = "*.csv")

n <- length(files)
df<-tibble()
  
  #row.names = c("Precision", "Recall", "Accuracy")) # x='string',y=1:10,z='string'


for(i in 1:n){
  x <- runAuthorStudyDummy(files[i])
  print(paste(x[1], x[2], x[3]))
  add_row(df, accuracy=x[1], precision=x[2], recall=x[3])
}


```

```{r}
df <- tibble(x = 1:3, y = 3:1)
dim(df)
df[3,1]="1231"

```


```{r}

data.frame([], row.names = c("Precision", "Recall", "Accuracy"))
r <- 3
newrow <- seq(4)
insertRow <- function(existingDF, newrow, r) {
  existingDF[seq(r+1,nrow(existingDF)+1),] <- existingDF[seq(r,nrow(existingDF)),]
  existingDF[r,] <- newrow
  existingDF
}

```


SCRATCH WORK
-----------------------------------------------------------------------------------------------------------------------
### Step 3: Cosine similarity
$$
similarity = cos(\theta) = \frac{A \cdot B}{\begin{Vmatrix}A\end{Vmatrix} \begin{Vmatrix}B\end{Vmatrix}} = \frac{\sum_{i=1}^n A_i B_i}{\sqrt{\sum_{i=1}^n A_i^2} \sqrt{\sum_{i=1}^n B_i^2}}
$$
```{r}

```


```{r}
library(stringr)
tb<- createCitationMatrix(text)
term <- tb %>%
  mutate(coauthor = str_replace_all(coauthor, " ", "")) %>%
  mutate(coauthor = str_replace_all(coauthor, ";", " ")) %>%
  mutate(journal = str_replace_all(journal, " ", "")) %>%
  mutate(term_col = paste(coauthor, journal, paper))

docs <- as.vector(term$term_col)
# journal <- tb %>%
#   transmute(journal = str_replace_all(journal, " ", ""))
# 
# combined <- paste(coauthors,journal,tb$paper)

```


```{r}

tb_author <- AKumar %>%
  tbl_df() %>%
  select(PaperID, AuthorID, Coauthor) %>%
  unnest_tokens(Author, Coauthor, token = stringr::str_split, pattern = '[;,]')

tb_title <- AKumar %>%
  tbl_df() %>%
  select(PaperID, AuthorID, Paper) %>%
  unnest_tokens(Words, Paper, token = "words", to_lower = TRUE, drop = TRUE)
  
tb_publication <- AKumar %>%
  tbl_df() %>%
  select(PaperID, AuthorID, Journal)

```


```{r}
test_case <- str_trim(unlist(str_split(authors[5],'[;,]')), side=c("both"))

x <- c()
for(i in 1:length(authors)){
  x <- append(x,str_split(authors[i],'[;,]'))
}
citationVocab <- unlist(x)
citationVocab <- str_trim(citationVocab, side=c("both"))
citationVocab <- unique(citationVocab)
```


```{r}
library(tidytext)
library(tibble)
titles <- as_tibble(AKumar$Paper, AKumar$PaperID)
paper_words <- titles %>%
  unnest_tokens(word,value) %>%
  count()

```
